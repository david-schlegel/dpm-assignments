# Agreeableness Plot
p1_a <- create_scatterplot(dat_scatterplots, "mean_bfi_agreeableness", "Agreeableness")
# Conscientiousness Plot
p2_c <- create_scatterplot(dat_scatterplots, "mean_bfi_conscientiousness", "Conscientiousness")
# Extraversion Plot
p3_e <- create_scatterplot(dat_scatterplots, "mean_bfi_extraversion", "Extraversion")
# Extraversion Plot
p4_o <- create_scatterplot(dat_scatterplots, "mean_bfi_openness", "Openness")
# Extraversion Plot
p5_n <- create_scatterplot(dat_scatterplots, "mean_bfi_neuroticism", "Neuroticism")
combined_plot <- p1_a + p2_c + p3_e + p4_o + p5_n + plot_layout(guides = 'collect')
combined_plot <- combined_plot + plot_layout(plot.margin = margin(5, 5, 5, 5))
combined_plot <- combined_plot + plot_annotation(title = 'Predicting IAT Scores from Personality Subscales',
subtitle = 'A Visualization of Multiple Linear Regressions')
print(combined_plot)
combined_plot <- p1_a + p2_c + p3_e + p4_o + p5_n + guide_area() + plot_layout(guides = 'collect')
combined_plot <- combined_plot + plot_layout(plot.margin = margin(5, 5, 5, 5))
combined_plot <- combined_plot + plot_annotation(title = 'Predicting IAT Scores from Personality Subscales',
subtitle = 'A Visualization of Multiple Linear Regressions')
print(combined_plot)
data_processed_after_exclusion <- data_processed_after_exclusion |>
mutate(extreme_scores_iat = ifelse(iat_d_score > quantile(iat_d_score, 0.9) | iat_d_score < quantile(iat_d_score, 0.1), "Extreme", "Not extreme"))
# to longer
dat_scatterplots <- data_processed_after_exclusion |>
select(unique_id, starts_with(c("mean_bfi")), iat_d_score, extreme_scores_iat) |>
pivot_longer(cols = starts_with("mean_bfi"), names_to = "subscales", values_to = "score")
# Load colors
wes_palette <- wes_palette("Zissou1", n = 5, type = "continuous")
# Function to create the scatterplot
create_scatterplot <- function(data, subscale, title) {
data |>
filter(subscales == subscale) |>
ggplot(aes(x = score, y = iat_d_score)) +
geom_point(aes(color = extreme_scores_iat, shape = extreme_scores_iat)) +
geom_smooth(method = "lm", se = FALSE, aes(group = 1), color = wes_palette[3]) +
scale_color_manual(values = c("Extreme" = wes_palette[2], "Not extreme" = wes_palette[1]),
name = "IAT-Score classification",
labels = c("Top/bottom 10% quantil", "10%-90% quantil")) +
theme_light() +
labs(x = "BFI Score", y = "IAT Score",
title = title,
color = "IAT Score Category", shape = "IAT Score Category") +
theme(axis.text = element_text(size = 10),
axis.title = element_text(size = 8),
plot.title = element_text(size = 10)) +
scale_shape_manual(values = c("Extreme" = 17, "Not extreme" = 16),
name = "IAT-Score classification",
labels = c("Top/bottom 10% quantil", "10%-90% quantil"))
}
# Agreeableness Plot
p1_a <- create_scatterplot(dat_scatterplots, "mean_bfi_agreeableness", "Agreeableness")
# Conscientiousness Plot
p2_c <- create_scatterplot(dat_scatterplots, "mean_bfi_conscientiousness", "Conscientiousness")
# Extraversion Plot
p3_e <- create_scatterplot(dat_scatterplots, "mean_bfi_extraversion", "Extraversion")
# Extraversion Plot
p4_o <- create_scatterplot(dat_scatterplots, "mean_bfi_openness", "Openness")
# Extraversion Plot
p5_n <- create_scatterplot(dat_scatterplots, "mean_bfi_neuroticism", "Neuroticism")
combined_plot <- p1_a + p2_c + p3_e + p4_o + p5_n + guide_area() + plot_layout(guides = 'collect')
combined_plot <- combined_plot + plot_annotation(
title = 'Predicting IAT Scores from Personality Subscales',
subtitle = 'A Visualization of Multiple Linear Regressions')
print(combined_plot)
# Faccetted Plots
my_labeller <- as_labeller(c(
mean_bfi_agreeableness = "Agreeableness",
mean_bfi_conscientiousness = "Conscientiousness",
mean_bfi_extraversion = "Extraversion",
mean_bfi_openness = "Openness",
mean_bfi_neuroticism = "Neuroticism"
))
ggplot(dat_scatterplots, aes(x = score, y = iat_d_score)) +
geom_point(aes(color = extreme_scores_iat, shape = extreme_scores_iat)) +
geom_smooth(method = "lm", se = FALSE, aes(group = 1), color = wes_palette[3]) +
scale_color_manual(
values = c("Extreme" = wes_palette[2], "Not extreme" = wes_palette[1]),
name = "IAT-Score classification",
labels = c("Top/bottom 10% quantil", "10%-90% quantil")) +
facet_wrap(~subscales, scales = "free", labeller = my_labeller) +
theme_light() +
labs(x = "BFI Subscale Score", y = "IAT Score",
title = "Predicting IAT Scores from Personality Subscales",
subtitle = "A Visualization of Multiple Linear Regressions",
color = "IAT Score Category", shape = "IAT Score Category") +
scale_shape_manual(
values = c("Extreme" = 17, "Not extreme" = 16),
name = "IAT-Score classification",
labels = c("Top/bottom 10% quantil", "10%-90% quantil")) +
theme(legend.position = c(0.98, 0.1),
legend.justification = c("right", "bottom"))
ggsave("scatterplot_bfi_iat.png")
ggsave("scatterplot_bfi_iat.pdf",  device = cairo_pdf, width = 10, height = 8)
combined_plot <- p1_a + p2_c + p3_e + p4_o + p5_n + guide_area() + plot_layout(guides = 'collect')
combined_plot <- combined_plot + plot_annotation(
title = "Predicting IAT Scores from Personality Subscales",
subtitle = "A Visualization of Multiple Linear Regressions")
print(combined_plot)
ggsave("../communication/combined_plot.png")
ggsave("../communication/combined_plot.pdf")
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(psych)
library(ggplot2)
library(easystats)
library(wesanderson)
library(patchwork)
data_processed <- read_csv("../data/processed/data_processed.csv")
#data_processed_after_exclusions <- data_processed |>
#  filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Sample after exclusions" = 1)) |>
kable_classic(full_width = FALSE)
# Age and SD Age
data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# Frequency and percentage of men vs. women
result_table <- data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100)) |>
mutate(percentage_gender = janitor::round_half_up(percentage_gender, digits = 2))
rownames(result_table) <- toupper(rownames(result_table))
result_table |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Proportion of demographics available
data_processed_after_exclusion |>
summarise(proportion_age = sum())
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Proportion with age info", "Proportion with gender info")) |>
kable_classic(full_width = FALSE)
View(result_table)
rownames(result_table) <- toupper(rownames(result_table))
View(result_table)
rownames(result_table) <- toupper(rownames(result_table))
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100),
percentage_gender = janitor::round_half_up(percentage_gender, digits = 2),
gender = toupper(gender)) |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100),
percentage_gender = janitor::round_half_up(percentage_gender, digits = 2),
gender = gender = str_to_title(gender)) |>
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100),
percentage_gender = janitor::round_half_up(percentage_gender, digits = 2),
gender = str_to_title(gender)) |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Proportion of demographics available
data_processed_after_exclusion |>
summarise(proportion_age = sum())
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Proportion with age info", "Proportion with gender info")) |>
kable_classic(full_width = FALSE)
kable(col.names = c("Age", "Gender")) |>
add_header_above(header = c("Proportion provided" = 2) |>
data_processed_after_exclusion |>
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Age", "Gender")) |>
add_header_above(header = c("Proportion provided" = 2) |>
kable_classic(full_width = FALSE)
data_processed_after_exclusion %>%
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate(across(everything(), ~janitor::round_half_up(., digits = 2))) |>
kable(col.names = c("Age", "Gender")) |>
add_header_above(c("Proportion provided" = 2)) |>
kable_classic(full_width = FALSE)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_raw_demographics.csv") |>
janitor::clean_names()
# big-5 Index
data_bfi_raw <- read_csv("../data/raw/data_raw_bfi.csv") |>
janitor::clean_names()
# Implicit association test
data_iat_raw <- read_csv("../data/raw/data_raw_iat.csv", skip = 1) |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
pivot_wider(names_from = variable,
values_from = response) |>
mutate(gender = sex,
gender = case_when(gender == "f" ~ "female",
gender == "m" ~ "male",
TRUE ~ "not indicated"),
age = as.character(age),
age = case_when(str_detect(age, "^[0-9]+$") ~ age,
TRUE ~ "not indicated")) |>
filter(unique_id != is.na(unique_id)) |>
select(-sex)
View(data_demographics_raw)
summarise(data_demographics_raw)
summary(data_bfi_raw)
summary(data_demographics_raw)
data_raw_demographics %>%
group_by(unique_id, variable) %>%
summarise(n = n(), .groups = "drop") %>%
filter(n > 1L)
View(dat_age_gender)
data_demographics_raw %>%
group_by(unique_id, variable) %>%
summarise(n = n(), .groups = "drop") %>%
filter(n > 1L)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_raw_demographics.csv") |>
janitor::clean_names()
# big-5 Index
data_bfi_raw <- read_csv("../data/raw/data_raw_bfi.csv") |>
janitor::clean_names()
# Implicit association test
data_iat_raw <- read_csv("../data/raw/data_raw_iat.csv", skip = 1) |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
pivot_wider(names_from = variable,
values_from = response) |>
mutate(gender = sex,
gender = case_when(gender == "f" ~ "female",
gender == "m" ~ "male",
TRUE ~ "not indicated"),
age = as.character(age),
age = case_when(str_detect(age, "^[0-9]+$") ~ age,
TRUE ~ "not indicated")) |>
filter(unique_id != is.na(unique_id)) |>
select(-sex)
# Function to recode negatively worded items
reverse_score <- function(x) {
case_when(
x == 1 ~ 6,
x == 2 ~ 5,
x == 3 ~ 4,
x == 4 ~ 3,
x == 5 ~ 2,
x == 6 ~ 1,
x == 0 ~ 0, # Question: why are there 0?
TRUE ~ NA_real_
)
}
dat_bfi <- data_bfi_raw |>
mutate(across(c(bfi_e2, bfi_e5, bfi_e7, bfi_c2, bfi_c4, bfi_c5, bfi_c9, bfi_n2, bfi_n5,
bfi_n7, bfi_a1, bfi_a3, bfi_a6, bfi_a8, bfi_o7, bfi_o9), ~ reverse_score(.),
.names = "{.col}_recode"))
# For mitigating copy & past errors build a vector with the used subscales original & recoded
sub_bfi_a <- c("bfi_a1_recode", "bfi_a2", "bfi_a3_recode", "bfi_a4", "bfi_a5", "bfi_a6_recode", "bfi_a7", "bfi_a8_recode", "bfi_a9")
sub_bfi_c <- c("bfi_c1", "bfi_c2_recode", "bfi_c3", "bfi_c4_recode", "bfi_c5_recode", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9_recode")
sub_bfi_e <- c("bfi_e1", "bfi_e2_recode", "bfi_e3", "bfi_e4", "bfi_e5_recode", "bfi_e6", "bfi_e7_recode", "bfi_e8")
sub_bfi_n <- c("bfi_n1", "bfi_n2_recode", "bfi_n3", "bfi_n4", "bfi_n5_recode", "bfi_n6", "bfi_n7_recode", "bfi_n8")
sub_bfi_o <- c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7_recode", "bfi_o8", "bfi_o9_recode", "bfi_o10")
dat_bif_recoded <- dat_bfi |>
select(unique_id, all_of(c(sub_bfi_a, sub_bfi_c, sub_bfi_e, sub_bfi_o, sub_bfi_n)))
sanity_check_bfi_scale <- function(data, scale_columns) {
cor_data <- data %>%
select(all_of(scale_columns)) %>%
cor(use = "complete.obs")
all(cor_data >= 0, na.rm = TRUE)
}
# Sanity-Checks for everiy BFI subscale
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_a)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_c)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_e)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_o)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_n)
# there is one negativ in openness, but it is close to zero and only between o7 and o10. Decision, still correct.
dat_bfi_scores_completeness <- dat_bif_recoded |>
rowwise() |>
mutate(exclude_min_max_scores = if_else(any((c_across(starts_with("bfi")) < 1 |
c_across(starts_with("bfi")) > 6),
na.rm = TRUE), "exclude", "include")) |>
select(unique_id, exclude_min_max_scores)
check_bfi_scale <- function(data, columns, threshold, col_name) {
data %>%
mutate(!!rlang::sym(col_name) := {
vals <- purrr::pmap(list(!!!rlang::syms(columns)), ~c(...))
purrr::map_chr(vals, function(x) {
if (all(is.na(x))) {
"include"
} else {
num_non_na <- sum(!is.na(x))
if (num_non_na >= threshold) {
"include"
} else {
"exclude"
}
}
})
})
}
dat_bfi_participant_completeness <- dat_bif_recoded |>
check_bfi_scale(sub_bfi_a, 9, "exclude_sub_bfi_agreeablenes") |>
check_bfi_scale(sub_bfi_c, 9, "exclude_sub_bfi_conscientiousness") |>
check_bfi_scale(sub_bfi_e, 8, "exclude_sub_bfi_extraversion") |>
check_bfi_scale(sub_bfi_o, 10, "exclude_sub_bfi_openness") |>
check_bfi_scale(sub_bfi_n, 8, "exclude_sub_bfi_neuroticism") |>
select(unique_id, c(starts_with("exclude")))
dat_bfi_means <- dat_bfi |>
mutate(mean_bfi_agreeableness = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_a))),
mean_bfi_conscientiousness = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_c))),
mean_bfi_extraversion = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_e))),
mean_bfi_neuroticism = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_o))),
mean_bfi_openness = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_n)))) |>
select(unique_id, starts_with("mean_bfi"))
# As the values are between 1 and 6 the mean can only be between 1 and six.
min_mean_score = 1
max_mean_score = 6
check_mean_score_range <- function(mean_score) {
mean_score >= min_mean_score & mean_score <= max_mean_score
}
check_values <- c(
check_mean_score_range(dat_bfi_means$mean_bfi_agreeableness),
check_mean_score_range(dat_bfi_means$mean_bfi_conscientiousness),
check_mean_score_range(dat_bfi_means$mean_bfi_extraversion),
check_mean_score_range(dat_bfi_means$mean_bfi_neuroticism),
check_mean_score_range(dat_bfi_means$mean_bfi_openness)
)
# number of true and false.
num_true <- sum(check_values, na.rm = TRUE)
num_false <- sum(!check_values, na.rm = FALSE)
list(number_of_true = num_true,
number_of_false = num_false)
View(data_iat_raw)
View(data_iat_raw)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(tidyverse)
library(janitor)
library(stringr)
library(openxlsx)
# demographics
data_demographics_raw <- read_csv("../data/raw/data_raw_demographics.csv") |>
janitor::clean_names()
# big-5 Index
data_bfi_raw <- read_csv("../data/raw/data_raw_bfi.csv") |>
janitor::clean_names()
# Implicit association test
data_iat_raw <- read_csv("../data/raw/data_raw_iat.csv", skip = 1) |>
janitor::clean_names()
dat_age_gender <- data_demographics_raw |>
pivot_wider(names_from = variable,
values_from = response) |>
mutate(gender = sex,
gender = case_when(gender == "f" ~ "female",
gender == "m" ~ "male",
TRUE ~ "not indicated"),
age = as.character(age),
age = case_when(str_detect(age, "^[0-9]+$") ~ age,
TRUE ~ "not indicated")) |>
filter(unique_id != is.na(unique_id)) |>
select(-sex)
# Function to recode negatively worded items
reverse_score <- function(x) {
case_when(
x == 1 ~ 6,
x == 2 ~ 5,
x == 3 ~ 4,
x == 4 ~ 3,
x == 5 ~ 2,
x == 6 ~ 1,
x == 0 ~ 0, # Question: why are there 0?
TRUE ~ NA_real_
)
}
dat_bfi <- data_bfi_raw |>
mutate(across(c(bfi_e2, bfi_e5, bfi_e7, bfi_c2, bfi_c4, bfi_c5, bfi_c9, bfi_n2, bfi_n5,
bfi_n7, bfi_a1, bfi_a3, bfi_a6, bfi_a8, bfi_o7, bfi_o9), ~ reverse_score(.),
.names = "{.col}_recode"))
# For mitigating copy & past errors build a vector with the used subscales original & recoded
sub_bfi_a <- c("bfi_a1_recode", "bfi_a2", "bfi_a3_recode", "bfi_a4", "bfi_a5", "bfi_a6_recode", "bfi_a7", "bfi_a8_recode", "bfi_a9")
sub_bfi_c <- c("bfi_c1", "bfi_c2_recode", "bfi_c3", "bfi_c4_recode", "bfi_c5_recode", "bfi_c6", "bfi_c7", "bfi_c8", "bfi_c9_recode")
sub_bfi_e <- c("bfi_e1", "bfi_e2_recode", "bfi_e3", "bfi_e4", "bfi_e5_recode", "bfi_e6", "bfi_e7_recode", "bfi_e8")
sub_bfi_n <- c("bfi_n1", "bfi_n2_recode", "bfi_n3", "bfi_n4", "bfi_n5_recode", "bfi_n6", "bfi_n7_recode", "bfi_n8")
sub_bfi_o <- c("bfi_o1", "bfi_o2", "bfi_o3", "bfi_o4", "bfi_o5", "bfi_o6", "bfi_o7_recode", "bfi_o8", "bfi_o9_recode", "bfi_o10")
dat_bif_recoded <- dat_bfi |>
select(unique_id, all_of(c(sub_bfi_a, sub_bfi_c, sub_bfi_e, sub_bfi_o, sub_bfi_n)))
sanity_check_bfi_scale <- function(data, scale_columns) {
cor_data <- data %>%
select(all_of(scale_columns)) %>%
cor(use = "complete.obs")
all(cor_data >= 0, na.rm = TRUE)
}
# Sanity-Checks for everiy BFI subscale
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_a)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_c)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_e)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_o)
sanity_check_bfi_scale(dat_bif_recoded, sub_bfi_n)
# there is one negativ in openness, but it is close to zero and only between o7 and o10. Decision, still correct.
dat_bfi_scores_completeness <- dat_bif_recoded |>
rowwise() |>
mutate(exclude_min_max_scores = if_else(any((c_across(starts_with("bfi")) < 1 |
c_across(starts_with("bfi")) > 6),
na.rm = TRUE), "exclude", "include")) |>
select(unique_id, exclude_min_max_scores)
check_bfi_scale <- function(data, columns, threshold, col_name) {
data %>%
mutate(!!rlang::sym(col_name) := {
vals <- purrr::pmap(list(!!!rlang::syms(columns)), ~c(...))
purrr::map_chr(vals, function(x) {
if (all(is.na(x))) {
"include"
} else {
num_non_na <- sum(!is.na(x))
if (num_non_na >= threshold) {
"include"
} else {
"exclude"
}
}
})
})
}
dat_bfi_participant_completeness <- dat_bif_recoded |>
check_bfi_scale(sub_bfi_a, 9, "exclude_sub_bfi_agreeablenes") |>
check_bfi_scale(sub_bfi_c, 9, "exclude_sub_bfi_conscientiousness") |>
check_bfi_scale(sub_bfi_e, 8, "exclude_sub_bfi_extraversion") |>
check_bfi_scale(sub_bfi_o, 10, "exclude_sub_bfi_openness") |>
check_bfi_scale(sub_bfi_n, 8, "exclude_sub_bfi_neuroticism") |>
select(unique_id, c(starts_with("exclude")))
dat_bfi_means <- dat_bfi |>
mutate(mean_bfi_agreeableness = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_a))),
mean_bfi_conscientiousness = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_c))),
mean_bfi_extraversion = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_e))),
mean_bfi_neuroticism = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_o))),
mean_bfi_openness = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_n)))) |>
select(unique_id, starts_with("mean_bfi"))
# As the values are between 1 and 6 the mean can only be between 1 and six.
min_mean_score = 1
max_mean_score = 6
check_mean_score_range <- function(mean_score) {
mean_score >= min_mean_score & mean_score <= max_mean_score
}
check_values <- c(
check_mean_score_range(dat_bfi_means$mean_bfi_agreeableness),
check_mean_score_range(dat_bfi_means$mean_bfi_conscientiousness),
check_mean_score_range(dat_bfi_means$mean_bfi_extraversion),
check_mean_score_range(dat_bfi_means$mean_bfi_neuroticism),
check_mean_score_range(dat_bfi_means$mean_bfi_openness)
)
# number of true and false.
num_true <- sum(check_values, na.rm = TRUE)
num_false <- sum(!check_values, na.rm = FALSE)
list(number_of_true = num_true,
number_of_false = num_false)
View(data_iat_raw)
dat_iat <- data_iat_raw |>
# code correct and incorrect to 1 and 0
mutate(trial_correct = case_when(trial_accuracy == "correct" ~ 1,
trial_accuracy == "incorrect" ~ 0,
TRUE ~ NA)) |>
filter(!block_number %in% c(1, 2, 5))
View(dat_iat)
# Calculations of mean and sd
dat_iat_d_scores <- dat_iat |>
group_by(unique_id) |>
summarise(mean1 = mean(trial_correct[block_number %in% c(3, 6)]),
mean2 = mean(trial_correct[block_number %in% c(4, 7)]),
sd_rt = sd(trial_correct),
# If sd is 0, then the formula is undefined. It is only 0 if all values are the same, either 0 or 1. D then is 0.
iat_d_score = ifelse(sd_rt == 0, 0, (mean2 - mean1) / sd_rt)) |>
select(unique_id, iat_d_score)
View(dat_iat_d_scores)

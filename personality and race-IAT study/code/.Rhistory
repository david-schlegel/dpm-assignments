select(unique_id, c(starts_with("sub_bfi_")))
dat_bfi_means <- dat_bfi |>
mutate(mean_bfi_a = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_a))),
mean_bfi_c = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_c))),
mean_bfi_e = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_e))),
mean_bfi_n = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_o))),
mean_bfi_o = rowMeans(select(dat_bif_recoded, all_of(sub_bfi_n)))) |>
select(unique_id, starts_with("mean_bfi"))
# As the values are between 1 and 6 the mean can only be between 1 and six.
min_mean_score = 1
max_mean_score = 6
check_mean_score_range <- function(mean_score) {
mean_score >= min_mean_score & mean_score <= max_mean_score
}
check_values <- c(
check_mean_score_range(dat_bfi_means$mean_bfi_a),
check_mean_score_range(dat_bfi_means$mean_bfi_c),
check_mean_score_range(dat_bfi_means$mean_bfi_e),
check_mean_score_range(dat_bfi_means$mean_bfi_n),
check_mean_score_range(dat_bfi_means$mean_bfi_o)
)
# number of true and false.
num_true <- sum(check_values, na.rm = TRUE)
num_false <- sum(!check_values, na.rm = FALSE)
list(number_of_true = num_true,
number_of_false = num_false)
dat_iat <- data_iat_raw |>
# code correct and incorrect to 1 and 0
mutate(trial_correct = case_when(trial_accuracy == "correct" ~ 1,
trial_accuracy == "incorrect" ~ 0,
TRUE ~ NA)) |>
filter(!block_number %in% c(1, 2, 5))
# Calculations of mean and sd
mean1 <- dat_iat |>
filter(block_number %in% c(3, 6)) |>
pull(trial_correct) |>
mean()
mean2 <- dat_iat |>
filter(block_number %in% c(4, 7)) |>
pull(trial_correct) |>
mean()
sd_rt <- dat_iat |>
pull(trial_correct) |>
sd()
# Calculate D-Score
d_score <- (mean2 - mean1) / sd_rt
# Sanity Check
if (d_score < -2 || d_score > 2) {
warning("D score is outside the expected range of -2 to +2. Revise the scoring implementation.")
}
# exclude participant with less than 120 trials
dat_iat_completeness <- dat_iat |>
group_by(unique_id) |>
count() |>
ungroup() |>
mutate(exclude_iat_completeness = ifelse(n == 120, "include", "exclude")) |>
select(-n)
# exclude participants wiht trial reaction less than 300
dat_iat_performance_mseconds <- dat_iat |>
mutate(latency_prob = if_else(trial_reaction_time_in_ms < 300, TRUE, FALSE)) |>
group_by(unique_id) |>
summarize(proportion_fast_trials_iat = mean(latency_prob)) |>
mutate(exclude_iat_msseconds = ifelse(proportion_fast_trials_iat > 0.10,
"exclude", "include")) |>
select(-proportion_fast_trials_iat)
#exclude participants with less than 75% accuracy
dat_iat_performance_accuracy <- dat_iat |>
group_by(unique_id) |>
summarise(mean_performance_accuracy = mean(trial_correct)) |>
mutate(exclude_iat_accuracy = ifelse(mean_performance_accuracy < 0.75,
"exclude", "include")) |>
select(-mean_performance_accuracy)
# left join demographics at the end so only the demographics of participants who filled out everything will be included.
data_processed_before_exlusions <- dat_bfi_scores_completness |>
full_join(dat_bfi_participant_completeness, by = "unique_id") |>
full_join(dat_iat_completeness, by = "unique_id") |>
full_join(dat_iat_performance_mseconds, by = "unique_id") |>
full_join(dat_iat_performance_accuracy, by = "unique_id") |>
full_join(dat_bfi_means, by = "unique_id") |>
full_join(dat_bif_recoded, by = "unique_id") |>
left_join(dat_age_gender, by = "unique_id")
data_processed <- data_processed_before_exlusions |>
mutate(exclude_participant = case_when(exclude_min_max_scores == "exclude" ~ "exclude",
sub_bfi_a == "exclude" ~ "exclude",
sub_bfi_c == "exclude" ~ "exclude",
sub_bfi_e == "exclude" ~ "exclude",
sub_bfi_o == "exclude" ~ "exclude",
sub_bfi_n == "exclude" ~ "exclude",
exclude_iat_completeness == "exclude" ~ "exclude",
exclude_iat_msseconds == "exclude" ~ "exclude",
exclude_iat_accuracy == "exclude" ~ "exclude",
TRUE ~ "include"))
# in case this dir doesn't exist, create it
dir.create("../data/processed/")
# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")
if(!file.exists("../data/processed/data_processed_codebook.xlsx")){
# convert the column names to a df
codebook_template <- data.frame(variable = colnames(data_processed)) |>
mutate(explanation = NA)
# write to disk as an excel file
openxlsx::write.xlsx(codebook_template, file = "../data/processed/data_processed_codebook.xlsx")
}
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(psych)
data_processed <- read_csv("../data/processed/data_processed.csv")
#data_processed_after_exclusions <- data_processed |>
#  filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Sample after exclusions" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
# Age and SD Age
data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100)) |>
mutate(percentage_gender = janitor::round_half_up(percentage_gender, digits = 2)) |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Proportion of demographics available
data_processed_after_exclusion |>
summarise(proportion_age = sum())
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Proportion with age info", "Proportion with gender info")) |>
kable_classic(full_width = FALSE)
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(psych)
data_processed <- read_csv("../data/processed/data_processed.csv")
#data_processed_after_exclusions <- data_processed |>
#  filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Sample after exclusions" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
# Age and SD Age
data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100)) |>
mutate(percentage_gender = janitor::round_half_up(percentage_gender, digits = 2)) |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Proportion of demographics available
data_processed_after_exclusion |>
summarise(proportion_age = sum())
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Proportion with age info", "Proportion with gender info")) |>
kable_classic(full_width = FALSE)
View(data_processed_after_exclusion)
alpha_bfi_agreeableness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_a"))) |>
alpha()
View(alpha_bfi_agreeableness)
print(alpha_bfi_agreeableness)
alpha_bfi_agreeableness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_a"))) |>
alpha()
alpha_bfi_conscientiousness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_c"))) |>
alpha()
alpha_bfi_extraversion <- data_processed_after_exclusion |>
select(starts_with(c("bfi_e"))) |>
alpha()
alpha_bfi_openness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_o"))) |>
alpha()
alpha_bfi_neuroticism <- data_processed_after_exclusion |>
select(starts_with(c("bfi_n"))) |>
alpha()
print(alpha_bfi_agreeableness)
print(alpha_bfi_conscientiousness)
print(alpha_bfi_extraversion)
print(alpha_bfi_openness)
print(alpha_bfi_neuroticism)
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(psych)
data_processed <- read_csv("../data/processed/data_processed.csv")
#data_processed_after_exclusions <- data_processed |>
#  filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Sample after exclusions" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
# Age and SD Age
data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100)) |>
mutate(percentage_gender = janitor::round_half_up(percentage_gender, digits = 2)) |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Proportion of demographics available
data_processed_after_exclusion |>
summarise(proportion_age = sum())
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Proportion with age info", "Proportion with gender info")) |>
kable_classic(full_width = FALSE)
alpha_bfi_agreeableness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_a"))) |>
alpha()
alpha_bfi_conscientiousness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_c"))) |>
alpha()
alpha_bfi_extraversion <- data_processed_after_exclusion |>
select(starts_with(c("bfi_e"))) |>
alpha()
alpha_bfi_openness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_o"))) |>
alpha()
alpha_bfi_neuroticism <- data_processed_after_exclusion |>
select(starts_with(c("bfi_n"))) |>
alpha()
print(alpha_bfi_agreeableness)
print(alpha_bfi_conscientiousness)
print(alpha_bfi_extraversion)
print(alpha_bfi_openness)
print(alpha_bfi_neuroticism)
View(data_processed_after_exclusion)
ggplot(data_processed_after_exclusions, aes(x = mean_bfi_a)) +
geom_histogram(binwidth = 1,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("Mean self-reported evaluation") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 7)) +
theme(panel.grid.minor = element_blank())
ggplot(data_processed_after_exclusion, aes(x = mean_bfi_a)) +
geom_histogram(binwidth = 1,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("Mean self-reported evaluation") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 7)) +
theme(panel.grid.minor = element_blank())
ggplot(data_processed_after_exclusion, aes(x = mean_bfi_a)) +
geom_histogram(binwidth = 1,
boundary = 0,
fill = viridis_pal(begin = 0.45, option = "mako")(1),
color = viridis_pal(begin = 0.30, option = "mako")(1)) +
xlab("Sub BFI Agreeableness") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 7)) +
theme(panel.grid.minor = element_blank())
install.packages("colorspace")
install.packages("colorspace")
library("colorspace")
pal <- choose_palette()
# set knit options
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
# disable scientific notation
options(scipen = 999)
library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(scales)
library(psych)
library(ggplot2)
data_processed <- read_csv("../data/processed/data_processed.csv")
#data_processed_after_exclusions <- data_processed |>
#  filter(exclude_participant == "include")
data_processed |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Whole sample" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
data_processed_after_exclusion <- data_processed |>
filter(exclude_participant == "include")
data_processed_after_exclusion |>
count(name = "n") |>
kable() |>
add_header_above(header = c("Sample after exclusions" = 1)) |> # note that you can add header rows to tables like this. The "1" indicates the number of columns the header should span. The sum of these numbers must equal the number of columns or you'll get an error.
kable_classic(full_width = FALSE)
# Age and SD Age
data_processed_after_exclusion |>
mutate(age = as.numeric(age)) |>
summarise(Mean = mean(age, na.rm = TRUE),
SD = sd(age, na.rm = TRUE)) |>
mutate_all(.funs = janitor::round_half_up, digits = 1) |>
kable() |>
add_header_above(header = c("Age" = 2)) |>
kable_classic(full_width = FALSE)
# Frequency and percentage of men vs. women
data_processed_after_exclusion |>
count(gender) |>
mutate(percentage_gender = (n / sum(n) * 100)) |>
mutate(percentage_gender = janitor::round_half_up(percentage_gender, digits = 2)) |>
kable(col.names = c("Gender", "Frequency", "Percentage Gender")) |>
kable_classic(full_width = FALSE)
# Proportion of demographics available
data_processed_after_exclusion |>
summarise(proportion_age = sum())
data_processed_after_exclusion |>
summarise(proportion_with_age_info = sum(age != "not indicated") / n(),
proportion_with_gender_info = sum(gender != "not indicated") / n()) |>
mutate_all(.funs = janitor::round_half_up, digits = 2) |>
kable(col.names = c("Proportion with age info", "Proportion with gender info")) |>
kable_classic(full_width = FALSE)
alpha_bfi_agreeableness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_a"))) |>
alpha()
alpha_bfi_conscientiousness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_c"))) |>
alpha()
alpha_bfi_extraversion <- data_processed_after_exclusion |>
select(starts_with(c("bfi_e"))) |>
alpha()
alpha_bfi_openness <- data_processed_after_exclusion |>
select(starts_with(c("bfi_o"))) |>
alpha()
alpha_bfi_neuroticism <- data_processed_after_exclusion |>
select(starts_with(c("bfi_n"))) |>
alpha()
print(alpha_bfi_agreeableness)
print(alpha_bfi_conscientiousness)
print(alpha_bfi_extraversion)
print(alpha_bfi_openness)
print(alpha_bfi_neuroticism)
# extract the data and put it into a long dataset
data_processed_after_exclusion_long_bfi <- data_processed_after_exclusion %>%
select(unique_id, starts_with("bfi")) %>%
pivot_longer(cols = starts_with("bfi"), names_to = "subscales", values_to = "score") %>%
drop_na()
# Agreeableness
data_processed_bfi_histogramm <- data_processed_after_exclusion_long_bfi |>
filter(subscales %in% grep("bfi_a", subscales, value = TRUE))
ggplot(data_processed_bfi_histogramm, aes(x = score, fill = subscales)) +
geom_histogram(binwidth = 1, boundary = 0,
fill = viridis_pal(begin = 0.5, option = "viridis")(1),
color = viridis_pal(begin = 0.6, option = "viridis")(1)) +
facet_wrap(~ subscales, scales = "free") +
xlab("Score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 6)) +
theme(panel.grid.minor = element_blank()) +
labs(title = "Subscale Agreeableness")
# Conscientiousness
data_processed_bfi_histogramm <- data_processed_after_exclusion_long_bfi |>
filter(subscales %in% grep("bfi_c", subscales, value = TRUE))
ggplot(data_processed_bfi_histogramm, aes(x = score, fill = subscales)) +
geom_histogram(binwidth = 1, boundary = 0,
fill = viridis_pal(begin = 0.5, option = "viridis")(1),
color = viridis_pal(begin = 0.6, option = "viridis")(1)) +
facet_wrap(~ subscales, scales = "free") +
xlab("Score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 6)) +
theme(panel.grid.minor = element_blank()) +
labs(title = "Subscale Conscientiousness")
# Extraversion
data_processed_bfi_histogramm <- data_processed_after_exclusion_long_bfi |>
filter(subscales %in% grep("bfi_e", subscales, value = TRUE))
ggplot(data_processed_bfi_histogramm, aes(x = score, fill = subscales)) +
geom_histogram(binwidth = 1, boundary = 0,
fill = viridis_pal(begin = 0.5, option = "viridis")(1),
color = viridis_pal(begin = 0.6, option = "viridis")(1)) +
facet_wrap(~ subscales, scales = "free") +
xlab("Score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 6)) +
theme(panel.grid.minor = element_blank()) +
labs(title = "Subscale Extraversion")
# Openness
data_processed_bfi_histogramm <- data_processed_after_exclusion_long_bfi |>
filter(subscales %in% grep("bfi_o", subscales, value = TRUE))
ggplot(data_processed_bfi_histogramm, aes(x = score, fill = subscales)) +
geom_histogram(binwidth = 1, boundary = 0,
fill = viridis_pal(begin = 0.5, option = "viridis")(1),
color = viridis_pal(begin = 0.6, option = "viridis")(1)) +
facet_wrap(~ subscales, scales = "free") +
xlab("Score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 6)) +
theme(panel.grid.minor = element_blank()) +
labs(title = "Subscale Openness")
# Neuroticism
data_processed_bfi_histogramm <- data_processed_after_exclusion_long_bfi |>
filter(subscales %in% grep("bfi_n", subscales, value = TRUE))
ggplot(data_processed_bfi_histogramm, aes(x = score, fill = subscales)) +
geom_histogram(binwidth = 1, boundary = 0,
fill = viridis_pal(begin = 0.5, option = "viridis")(1),
color = viridis_pal(begin = 0.6, option = "viridis")(1)) +
facet_wrap(~ subscales, scales = "free") +
xlab("Score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
coord_cartesian(xlim = c(1, 6)) +
theme(panel.grid.minor = element_blank()) +
labs(title = "Subscale Neuroticism")
data_processed_after_exclusion |>
ggplot(aes(x = iat_d_score)) +
geom_histogram(binwidth = 0.05,
fill = viridis_pal(begin = 0.8, option = "viridis")(1),
color = viridis_pal(begin = 0.85, option = "viridis")(1)) +
xlab("D-score") +
ylab("Frequency") +
theme_linedraw() +
scale_x_continuous(breaks = pretty_breaks(n = 7)) +
theme(panel.grid.minor = element_blank()) +
labs(title = "D-Score IAT")
cor_matrix <- data_processed_after_exclusion %>%
select(starts_with("mean_bfi"), iat_d_score) %>%
cor(use = "pairwise.complete.obs", method = "pearson")
print(cor_matrix)
cor_matrix <- data_processed_after_exclusion |>
select(starts_with("mean_bfi"), iat_d_score) |>
cor(use = "pairwise.complete.obs", method = "pearson") |>
round(2)
print(cor_matrix)
